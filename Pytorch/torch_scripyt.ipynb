{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/lrbonta/Academic-Projects/Pytorch/torch_scripyt.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lrbonta/Academic-Projects/Pytorch/torch_scripyt.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.12.1-cp39-cp39-manylinux1_x86_64.whl (776.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 776.4 MB 62 kB/s  eta 0:00:01     |██████████▋                     | 258.0 MB 2.0 MB/s eta 0:04:20     |█████████████████▏              | 417.5 MB 1.2 MB/s eta 0:04:57     |█████████████████████▌          | 520.8 MB 2.6 MB/s eta 0:01:37█████▍ | 738.3 MB 5.4 MB/s eta 0:00:08     |██████████████████████████████▋ | 742.0 MB 2.7 MB/s eta 0:00:13\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/lrbonta/anaconda3/lib/python3.9/site-packages (from torch) (4.1.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/lrbonta/Academic-Projects/Pytorch/torch_scripyt.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/lrbonta/Academic-Projects/Pytorch/torch_scripyt.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.13.1-cp39-cp39-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.1 MB 1.2 MB/s eta 0:00:01     |██████████████████████████▎     | 15.7 MB 1.3 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/lrbonta/anaconda3/lib/python3.9/site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: torch==1.12.1 in /home/lrbonta/anaconda3/lib/python3.9/site-packages (from torchvision) (1.12.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/lrbonta/anaconda3/lib/python3.9/site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: typing-extensions in /home/lrbonta/anaconda3/lib/python3.9/site-packages (from torchvision) (4.1.1)\n",
      "Requirement already satisfied: numpy in /home/lrbonta/anaconda3/lib/python3.9/site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lrbonta/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/lrbonta/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lrbonta/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/lrbonta/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18()\n",
    "example = torch.rand(1, 3, 224, 224)\n",
    "traced_script_module = torch.jit.trace(model, example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  original_name=ResNet\n",
       "  (conv1): Conv2d(original_name=Conv2d)\n",
       "  (bn1): BatchNorm2d(original_name=BatchNorm2d)\n",
       "  (relu): ReLU(original_name=ReLU)\n",
       "  (maxpool): MaxPool2d(original_name=MaxPool2d)\n",
       "  (layer1): Sequential(\n",
       "    original_name=Sequential\n",
       "    (0): BasicBlock(\n",
       "      original_name=BasicBlock\n",
       "      (conv1): Conv2d(original_name=Conv2d)\n",
       "      (bn1): BatchNorm2d(original_name=BatchNorm2d)\n",
       "      (relu): ReLU(original_name=ReLU)\n",
       "      (conv2): Conv2d(original_name=Conv2d)\n",
       "      (bn2): BatchNorm2d(original_name=BatchNorm2d)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      original_name=BasicBlock\n",
       "      (conv1): Conv2d(original_name=Conv2d)\n",
       "      (bn1): BatchNorm2d(original_name=BatchNorm2d)\n",
       "      (relu): ReLU(original_name=ReLU)\n",
       "      (conv2): Conv2d(original_name=Conv2d)\n",
       "      (bn2): BatchNorm2d(original_name=BatchNorm2d)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    original_name=Sequential\n",
       "    (0): BasicBlock(\n",
       "      original_name=BasicBlock\n",
       "      (conv1): Conv2d(original_name=Conv2d)\n",
       "      (bn1): BatchNorm2d(original_name=BatchNorm2d)\n",
       "      (relu): ReLU(original_name=ReLU)\n",
       "      (conv2): Conv2d(original_name=Conv2d)\n",
       "      (bn2): BatchNorm2d(original_name=BatchNorm2d)\n",
       "      (downsample): Sequential(\n",
       "        original_name=Sequential\n",
       "        (0): Conv2d(original_name=Conv2d)\n",
       "        (1): BatchNorm2d(original_name=BatchNorm2d)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      original_name=BasicBlock\n",
       "      (conv1): Conv2d(original_name=Conv2d)\n",
       "      (bn1): BatchNorm2d(original_name=BatchNorm2d)\n",
       "      (relu): ReLU(original_name=ReLU)\n",
       "      (conv2): Conv2d(original_name=Conv2d)\n",
       "      (bn2): BatchNorm2d(original_name=BatchNorm2d)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    original_name=Sequential\n",
       "    (0): BasicBlock(\n",
       "      original_name=BasicBlock\n",
       "      (conv1): Conv2d(original_name=Conv2d)\n",
       "      (bn1): BatchNorm2d(original_name=BatchNorm2d)\n",
       "      (relu): ReLU(original_name=ReLU)\n",
       "      (conv2): Conv2d(original_name=Conv2d)\n",
       "      (bn2): BatchNorm2d(original_name=BatchNorm2d)\n",
       "      (downsample): Sequential(\n",
       "        original_name=Sequential\n",
       "        (0): Conv2d(original_name=Conv2d)\n",
       "        (1): BatchNorm2d(original_name=BatchNorm2d)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      original_name=BasicBlock\n",
       "      (conv1): Conv2d(original_name=Conv2d)\n",
       "      (bn1): BatchNorm2d(original_name=BatchNorm2d)\n",
       "      (relu): ReLU(original_name=ReLU)\n",
       "      (conv2): Conv2d(original_name=Conv2d)\n",
       "      (bn2): BatchNorm2d(original_name=BatchNorm2d)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    original_name=Sequential\n",
       "    (0): BasicBlock(\n",
       "      original_name=BasicBlock\n",
       "      (conv1): Conv2d(original_name=Conv2d)\n",
       "      (bn1): BatchNorm2d(original_name=BatchNorm2d)\n",
       "      (relu): ReLU(original_name=ReLU)\n",
       "      (conv2): Conv2d(original_name=Conv2d)\n",
       "      (bn2): BatchNorm2d(original_name=BatchNorm2d)\n",
       "      (downsample): Sequential(\n",
       "        original_name=Sequential\n",
       "        (0): Conv2d(original_name=Conv2d)\n",
       "        (1): BatchNorm2d(original_name=BatchNorm2d)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      original_name=BasicBlock\n",
       "      (conv1): Conv2d(original_name=Conv2d)\n",
       "      (bn1): BatchNorm2d(original_name=BatchNorm2d)\n",
       "      (relu): ReLU(original_name=ReLU)\n",
       "      (conv2): Conv2d(original_name=Conv2d)\n",
       "      (bn2): BatchNorm2d(original_name=BatchNorm2d)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(original_name=AdaptiveAvgPool2d)\n",
       "  (fc): Linear(original_name=Linear)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_script_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.torchvision.models.resnet.___torch_mangle_228.ResNet,\n",
       "      %x.1 : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cpu)):\n",
       "  %fc : __torch__.torch.nn.modules.linear.___torch_mangle_227.Linear = prim::GetAttr[name=\"fc\"](%self.1)\n",
       "  %avgpool : __torch__.torch.nn.modules.pooling.___torch_mangle_226.AdaptiveAvgPool2d = prim::GetAttr[name=\"avgpool\"](%self.1)\n",
       "  %layer4 : __torch__.torch.nn.modules.container.___torch_mangle_225.Sequential = prim::GetAttr[name=\"layer4\"](%self.1)\n",
       "  %layer3 : __torch__.torch.nn.modules.container.___torch_mangle_209.Sequential = prim::GetAttr[name=\"layer3\"](%self.1)\n",
       "  %layer2 : __torch__.torch.nn.modules.container.___torch_mangle_193.Sequential = prim::GetAttr[name=\"layer2\"](%self.1)\n",
       "  %layer1 : __torch__.torch.nn.modules.container.___torch_mangle_177.Sequential = prim::GetAttr[name=\"layer1\"](%self.1)\n",
       "  %maxpool : __torch__.torch.nn.modules.pooling.___torch_mangle_164.MaxPool2d = prim::GetAttr[name=\"maxpool\"](%self.1)\n",
       "  %relu.1 : __torch__.torch.nn.modules.activation.___torch_mangle_163.ReLU = prim::GetAttr[name=\"relu\"](%self.1)\n",
       "  %bn1.1 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_162.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%self.1)\n",
       "  %conv1.1 : __torch__.torch.nn.modules.conv.___torch_mangle_161.Conv2d = prim::GetAttr[name=\"conv1\"](%self.1)\n",
       "  %1613 : Tensor = prim::CallMethod[name=\"forward\"](%conv1.1, %x.1)\n",
       "  %1614 : Tensor = prim::CallMethod[name=\"forward\"](%bn1.1, %1613)\n",
       "  %1615 : Tensor = prim::CallMethod[name=\"forward\"](%relu.1, %1614)\n",
       "  %1616 : Tensor = prim::CallMethod[name=\"forward\"](%maxpool, %1615)\n",
       "  %1617 : Tensor = prim::CallMethod[name=\"forward\"](%layer1, %1616)\n",
       "  %1618 : Tensor = prim::CallMethod[name=\"forward\"](%layer2, %1617)\n",
       "  %1619 : Tensor = prim::CallMethod[name=\"forward\"](%layer3, %1618)\n",
       "  %1620 : Tensor = prim::CallMethod[name=\"forward\"](%layer4, %1619)\n",
       "  %1621 : Tensor = prim::CallMethod[name=\"forward\"](%avgpool, %1620)\n",
       "  %1270 : int = prim::Constant[value=1]() # /home/lrbonta/anaconda3/lib/python3.9/site-packages/torchvision/models/resnet.py:279:0\n",
       "  %1271 : int = prim::Constant[value=-1]() # /home/lrbonta/anaconda3/lib/python3.9/site-packages/torchvision/models/resnet.py:279:0\n",
       "  %input : Float(1, 512, strides=[512, 1], requires_grad=1, device=cpu) = aten::flatten(%1621, %1270, %1271) # /home/lrbonta/anaconda3/lib/python3.9/site-packages/torchvision/models/resnet.py:279:0\n",
       "  %1622 : Tensor = prim::CallMethod[name=\"forward\"](%fc, %input)\n",
       "  return (%1622)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_script_module.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def forward(self,\\n    x: Tensor) -> Tensor:\\n  fc = self.fc\\n  avgpool = self.avgpool\\n  layer4 = self.layer4\\n  layer3 = self.layer3\\n  layer2 = self.layer2\\n  layer1 = self.layer1\\n  maxpool = self.maxpool\\n  relu = self.relu\\n  bn1 = self.bn1\\n  conv1 = self.conv1\\n  _0 = (relu).forward((bn1).forward((conv1).forward(x, ), ), )\\n  _1 = (layer1).forward((maxpool).forward(_0, ), )\\n  _2 = (layer3).forward((layer2).forward(_1, ), )\\n  _3 = (avgpool).forward((layer4).forward(_2, ), )\\n  input = torch.flatten(_3, 1)\\n  return (fc).forward(input, )\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_script_module.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= traced_script_module.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def forward(self,\\n    x: Tensor) -> Tensor:\\n  fc = self.fc\\n  avgpool = self.avgpool\\n  layer4 = self.layer4\\n  layer3 = self.layer3\\n  layer2 = self.layer2\\n  layer1 = self.layer1\\n  maxpool = self.maxpool\\n  relu = self.relu\\n  bn1 = self.bn1\\n  conv1 = self.conv1\\n  _0 = (relu).forward((bn1).forward((conv1).forward(x, ), ), )\\n  _1 = (layer1).forward((maxpool).forward(_0, ), )\\n  _2 = (layer3).forward((layer2).forward(_1, ), )\\n  _3 = (avgpool).forward((layer4).forward(_2, ), )\\n  input = torch.flatten(_3, 1)\\n  return (fc).forward(input, )\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  fc = self.fc\n",
      "  avgpool = self.avgpool\n",
      "  layer4 = self.layer4\n",
      "  layer3 = self.layer3\n",
      "  layer2 = self.layer2\n",
      "  layer1 = self.layer1\n",
      "  maxpool = self.maxpool\n",
      "  relu = self.relu\n",
      "  bn1 = self.bn1\n",
      "  conv1 = self.conv1\n",
      "  _0 = (relu).forward((bn1).forward((conv1).forward(x, ), ), )\n",
      "  _1 = (layer1).forward((maxpool).forward(_0, ), )\n",
      "  _2 = (layer3).forward((layer2).forward(_1, ), )\n",
      "  _3 = (avgpool).forward((layer4).forward(_2, ), )\n",
      "  input = torch.flatten(_3, 1)\n",
      "  return (fc).forward(input, )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = traced_script_module(torch.ones(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5517, -0.5225,  0.5920,  0.3906,  0.3982,  0.5635, -0.4512,  1.4039,\n",
      "          0.1816, -0.4333, -1.0825, -0.2643, -0.4691, -0.1852,  0.1376,  0.0134,\n",
      "          0.4773, -0.2599,  0.1856,  0.1556,  1.0813, -0.1790, -0.9239, -0.5415,\n",
      "          0.5140,  0.0745, -0.2510, -0.9034, -0.2131,  0.2323,  0.1773, -0.1383,\n",
      "         -0.3795,  0.3616,  0.8814, -0.0898, -0.0995,  0.3288, -0.6358,  0.1506,\n",
      "          0.9189, -0.1161,  0.3675, -0.0084, -0.1971,  0.0051,  1.4167, -0.3051,\n",
      "         -0.5461, -0.5301, -0.1102, -0.4371,  0.0583, -0.0316, -0.0717, -0.1986,\n",
      "         -0.3325,  1.0996, -0.1769, -0.0371, -0.7371, -0.1500, -0.3269, -0.3681,\n",
      "          0.3659,  0.3317, -0.1229, -1.2280, -0.4951,  0.3693, -0.7780,  0.1073,\n",
      "          0.1855,  0.0251,  0.6183, -0.8852, -0.8573,  0.7723,  0.2852, -0.4410,\n",
      "         -0.3594,  1.1598,  0.2049, -0.2423,  0.2371, -0.1329,  0.1851, -0.2857,\n",
      "         -0.4769, -0.3049,  0.7791,  0.2492,  0.1957,  0.1762,  0.1059,  0.2595,\n",
      "         -0.0698, -0.2131, -0.4845,  0.2884,  0.5458,  0.2430,  0.1714, -0.5454,\n",
      "         -0.5985,  0.0957,  0.3609, -0.2826, -0.7263, -0.0082, -0.1605,  0.5614,\n",
      "          0.8408,  0.1937, -0.3943, -0.1716,  0.2855, -0.6199, -0.1252,  0.2599,\n",
      "         -0.4229, -0.5142,  0.3397, -0.2813, -0.4471, -0.2464, -0.3475, -0.9217,\n",
      "          0.1932, -0.0539, -0.2970,  0.7785,  0.0661,  0.2429,  0.0977, -1.0615,\n",
      "         -0.8534,  0.6088,  0.8444, -0.1883, -0.2165, -0.2193, -0.6602, -0.1264,\n",
      "         -0.6096,  0.6549, -0.7244, -0.2664, -0.0846, -0.1241, -0.1923,  0.0673,\n",
      "          0.8631, -0.8029,  0.7257,  0.0280, -0.5149, -0.7191,  0.5589,  0.6803,\n",
      "          0.3658,  0.9963,  0.3891,  0.0938, -0.4704, -0.2820, -0.3475, -0.2599,\n",
      "         -0.2418,  0.1191, -0.5606,  1.0405,  0.9092, -0.0430, -0.0424, -0.5410,\n",
      "         -0.5914, -0.0633,  0.0628,  0.2300,  0.0853,  0.4266, -1.1601,  1.0766,\n",
      "          0.5795, -0.3272, -0.2210,  0.0582, -0.5642, -0.1075, -0.7861, -0.1141,\n",
      "         -0.5994,  0.5816,  0.6390, -1.0460,  0.7835, -0.3450, -0.4802,  0.4032,\n",
      "         -0.7244,  0.4147, -0.7789, -1.2165,  0.0102, -0.1612,  0.5384, -0.5244,\n",
      "          0.5187, -1.1323, -0.2110,  0.9068,  0.7316,  0.5144, -1.1879,  0.1929,\n",
      "          0.3591,  0.4041,  0.1116, -0.5797,  0.0166,  0.9233, -0.8533,  0.3541,\n",
      "         -0.3671, -0.0697, -0.5484,  0.7016,  0.8710,  0.3746, -0.1186,  0.2983,\n",
      "          0.5653,  0.6134,  0.6500, -0.6846, -0.1003, -0.2338,  0.0535, -0.4642,\n",
      "         -0.5981,  0.5499,  0.8379,  0.0032, -0.7689,  1.0303,  0.0361,  0.0437,\n",
      "          0.3502, -0.3118,  0.7548,  0.2282,  0.7697,  0.1801,  0.2003, -0.9647,\n",
      "          0.4176,  0.7170, -0.1640, -0.4221, -0.0438, -0.4084,  0.0974,  0.2834,\n",
      "         -0.0962, -0.5362,  0.2611,  0.7041,  1.1964, -0.4536,  0.0916,  0.5030,\n",
      "         -1.2288, -0.4719,  0.6621,  0.8925, -0.3651, -0.1888,  0.5705,  0.3789,\n",
      "         -0.0228, -0.2394, -0.6397, -0.0586,  0.7727, -0.3315, -0.5998,  0.4702,\n",
      "          0.0398,  0.4066,  0.3090, -0.8595, -0.4838,  0.4376,  0.8034, -0.2093,\n",
      "          0.6399, -0.2029,  0.4824,  0.2849, -0.1358,  0.1157, -0.7886,  0.2310,\n",
      "          0.7404, -0.6770, -0.5955,  0.8896,  0.8236, -1.1433, -0.1144,  0.8427,\n",
      "          0.1090,  0.4300, -0.0134,  0.4756,  0.8130,  0.8422,  1.2346, -0.3570,\n",
      "          0.6048, -0.0063, -0.3445, -0.4361,  0.5406, -0.4450, -0.2114, -0.3189,\n",
      "         -0.9348, -0.4732, -0.9083,  0.3042, -0.3361, -0.4184, -0.2946, -0.0258,\n",
      "          0.2729,  0.2380,  0.4014, -0.1841,  0.4107,  0.3156, -0.7753, -0.5973,\n",
      "         -0.3968, -0.0461,  0.4513, -0.2154,  0.5040, -0.2693,  0.5350, -0.4314,\n",
      "          0.3565, -0.2382, -0.9638,  0.7316,  0.1334, -0.3984,  0.9126, -0.1041,\n",
      "          0.6578,  0.4243,  0.0231, -0.8719,  0.4357, -0.1291,  0.0537,  0.2944,\n",
      "          0.0309,  0.1741, -0.5144, -0.9961, -0.7936, -0.0663, -0.1249,  0.2709,\n",
      "          0.0805, -0.7743,  0.4801,  0.2382, -0.4342,  1.0022, -0.6240,  0.1376,\n",
      "          0.0461, -0.2872,  0.0222,  0.6231,  0.1036, -0.1381,  0.0028, -0.3405,\n",
      "          0.3472,  0.5984, -0.1310, -0.1083, -0.2696,  0.8805,  0.7245,  0.0024,\n",
      "          0.1340, -0.4192, -0.9684, -0.4389, -0.5626,  0.1653,  0.4136,  0.1717,\n",
      "         -0.5338,  0.5555,  0.3400,  0.3159, -0.6371, -0.6608,  0.2223, -0.2884,\n",
      "          0.4078,  0.8659, -0.2777,  1.0048, -0.2758,  0.1405,  0.1051,  0.1879,\n",
      "          0.3086,  0.5921,  0.2250, -0.1948,  0.2378,  0.0492,  0.4229, -0.7367,\n",
      "         -0.0549,  0.3774, -0.3989, -0.2337, -0.2324,  0.0032,  0.6442, -0.0916,\n",
      "         -0.2446,  0.6750, -0.5692, -0.6930, -0.1104, -0.0728,  0.2824,  0.6628,\n",
      "         -0.0951,  0.5381, -0.1501,  0.7831,  0.4457,  0.8598,  0.5381, -0.2954,\n",
      "         -0.0148,  0.0261, -0.5349,  0.3287, -0.0944, -0.1441,  0.4144,  0.0196,\n",
      "         -0.3734, -0.6093,  0.8583, -0.4055,  0.1419, -0.0246,  0.2898,  0.0578,\n",
      "          0.6689,  0.1756, -0.0942,  0.5335,  0.4615,  0.4331, -0.3296, -0.5788,\n",
      "         -0.0202,  0.4526,  0.3725,  0.2863, -0.8597, -0.3986,  0.9550, -0.1028,\n",
      "          0.1121,  0.8339,  0.1131, -0.1653,  0.5610, -0.0119, -0.1452,  0.1056,\n",
      "         -0.5083,  0.5587, -1.0649, -0.5575,  0.2061, -0.9149, -0.1988,  0.4553,\n",
      "         -0.0398,  0.0655,  0.0897, -0.4324,  0.3381, -0.8732,  0.9168,  0.3954,\n",
      "          0.2012, -0.5766, -0.0852,  0.2869, -0.2399, -0.9818,  0.2882, -0.0363,\n",
      "         -0.4605, -0.7591,  0.4908,  0.3954,  0.6003, -0.5054,  0.3277,  0.4732,\n",
      "         -0.2606,  0.1452,  0.0240, -0.2098,  0.2210, -0.0081,  0.9974,  0.7086,\n",
      "         -0.9622,  0.5187, -0.1052, -0.2269,  0.0811, -0.2720,  0.1896,  0.3939,\n",
      "          0.4655, -0.1429,  0.9272,  0.5746,  0.1090, -0.6671, -0.3092, -0.1073,\n",
      "          0.3615,  0.2272,  0.2680,  0.1992, -0.3478,  0.1579,  0.5865, -0.3984,\n",
      "         -0.4276,  0.7013,  0.0063, -0.2488,  0.8446,  0.8937, -0.4414, -0.8007,\n",
      "          0.1130,  0.5009,  0.1154,  0.2152, -0.5473,  0.3963, -0.1817, -0.0691,\n",
      "         -0.0427, -0.4697, -1.0846,  0.2586,  0.6632,  0.2207,  0.1277, -0.1548,\n",
      "         -0.3354,  0.4142,  0.5761, -0.0524, -0.1177, -0.1300,  0.4157,  0.1564,\n",
      "         -0.2994,  0.3241, -0.7250, -0.3028, -0.3407,  0.5661, -0.0516,  0.0911,\n",
      "          0.3927,  0.2972,  0.7473, -0.1526,  0.5663,  0.1710,  0.1996,  0.2239,\n",
      "          0.0531, -0.1726,  1.0266,  0.1538,  0.4762, -0.3714, -0.1540,  0.1411,\n",
      "          0.5527,  0.1914,  0.0789, -0.2170, -0.3685,  0.4791,  0.4921, -0.2365,\n",
      "         -0.3155, -0.4035,  0.1107,  0.2383, -0.5247, -0.1766, -0.4779, -0.3472,\n",
      "         -0.1629, -0.3761,  0.0271, -0.4401, -0.4998, -0.2034,  0.3887,  0.7674,\n",
      "         -0.5248, -0.0612, -1.0589,  0.0856, -0.6223,  1.0911, -0.9154,  1.1239,\n",
      "         -0.1679,  0.1251, -0.9215, -0.0788, -0.4202,  0.6242,  0.0312,  1.3774,\n",
      "          0.3365,  0.0371, -0.2760, -0.5306,  0.8968,  0.3026, -0.2490, -0.1846,\n",
      "          0.3035, -0.1998, -0.0036,  0.5236, -0.0876,  0.0881, -0.0889, -0.4507,\n",
      "          0.1740,  0.1953,  0.0492, -0.4408,  0.3336, -0.3063, -0.0202,  0.7487,\n",
      "          0.1121,  0.6877, -0.8447,  0.2094,  0.1050,  0.4992, -0.0520,  0.1508,\n",
      "          0.3019, -0.1815,  0.7120,  0.0151, -0.3937, -0.5742,  0.7179, -0.5234,\n",
      "         -0.5445, -0.5102, -1.0518, -0.5806,  0.0331, -0.0669,  0.0243,  0.4641,\n",
      "          0.1353, -0.0367, -0.0439, -0.0027, -0.2569, -0.4265,  0.2891, -0.0673,\n",
      "          0.4437,  0.1737,  0.4469, -0.3615,  0.1933,  0.2944, -0.4284,  0.4729,\n",
      "          0.4089, -0.1437, -0.8182, -0.0583, -0.7009, -0.5638, -0.4472,  0.8787,\n",
      "         -1.1150,  0.1828,  0.1151,  0.7124, -0.4419, -1.3398, -0.7755, -0.6247,\n",
      "          0.3258,  0.4204,  0.5454, -0.8647, -0.1200, -0.6745, -0.2694, -0.4080,\n",
      "         -0.5054,  0.3681,  0.7544,  0.3430,  0.0531,  0.6393, -0.2496, -0.3924,\n",
      "          0.2663,  0.1745,  0.4564,  0.4587, -0.1820,  0.1603, -0.1068, -0.5242,\n",
      "          0.3052,  0.3466, -0.0904, -0.0136,  0.2154,  0.7114,  0.2073, -0.2253,\n",
      "          0.2649,  0.0874,  0.8707, -0.6639,  0.6367, -0.2444,  0.8545,  0.1212,\n",
      "          1.0202, -0.0529, -0.2204,  0.1584, -0.0930,  0.0532, -1.0696, -0.0523,\n",
      "          0.2334, -0.0680,  0.4979, -0.4829, -0.3566, -0.0459,  0.6527,  0.2121,\n",
      "          0.2272, -0.6814, -0.3613,  0.2741, -0.2401,  0.1983,  0.2222,  1.0503,\n",
      "         -0.4846,  0.5961, -0.1694,  0.4072, -0.1816, -0.2889,  0.5069,  0.8842,\n",
      "         -0.4233, -0.6211,  0.5077, -0.1877, -0.5159, -0.4978, -0.8079,  0.3087,\n",
      "         -0.6222, -0.0458,  0.4378,  0.3064,  0.4646, -0.2376, -0.0349,  0.8964,\n",
      "          0.1203, -0.4795,  0.2408, -0.6452, -0.5000,  0.8130,  0.2693,  0.4991,\n",
      "          0.0368,  0.8029,  0.1285, -0.1152,  0.8794, -0.5811, -0.2426, -0.2184,\n",
      "          0.4642,  0.5793, -0.6543, -0.0491, -1.4762, -0.0139, -0.5761, -0.3333,\n",
      "          0.3483,  0.2491,  0.2534, -0.0691,  0.2250, -0.3809, -0.7149,  0.2578,\n",
      "         -0.1270,  0.4564,  0.4988,  0.1970,  0.6289,  0.0317,  0.0414,  0.0278,\n",
      "         -0.1242,  0.6275, -0.0027, -0.2822, -0.6869,  0.1277,  0.5697,  0.7521,\n",
      "         -0.1774, -0.6697,  0.2400,  0.1269, -0.0313,  0.3682, -0.2004,  0.2528,\n",
      "         -0.2629,  0.8808, -1.2756, -0.0073, -0.0470, -0.4812,  0.5951,  0.0459,\n",
      "          0.1777, -0.1556, -0.2230, -0.5172,  0.9517, -0.3953,  0.7624,  0.0863,\n",
      "          0.5471,  0.6887, -0.2818,  0.2932, -0.5647, -0.4672,  0.4569, -0.0266,\n",
      "          0.2936,  0.1637,  0.0203,  0.0104, -0.8547, -0.2297, -0.6801,  0.2800,\n",
      "          0.1484,  0.2937, -0.0804, -0.3772,  0.5568,  0.3899,  0.1080,  0.0506,\n",
      "          0.1207,  0.0163,  0.6306,  1.1633,  0.5364,  0.4948, -0.1233, -1.3350,\n",
      "          0.6432,  0.6624, -0.0276, -0.1902,  0.1178, -0.4327,  0.1598, -0.0845,\n",
      "          0.7006, -0.2668, -0.5515, -0.8972, -0.3907, -0.0845,  0.0596, -0.3210,\n",
      "         -0.2349,  0.9957, -0.1724,  0.2221,  0.0229, -0.2278, -0.4215,  0.2155,\n",
      "          0.6163,  0.6926,  0.2954,  0.0358,  0.5298,  0.0572, -0.6402,  0.5029,\n",
      "          0.4077,  0.8941, -0.2099, -0.7717,  0.0483,  0.5800,  0.7076, -0.1516,\n",
      "          0.5642, -0.0576,  0.2238,  1.3665,  0.4842,  0.2405, -0.3076, -0.2532,\n",
      "          0.0089, -0.4249, -0.2496, -0.0269,  0.4388, -0.0034,  0.4109,  0.2454,\n",
      "         -0.3120, -0.0145, -0.3837,  0.6328,  0.0982, -0.1414,  0.2844,  0.1351,\n",
      "         -0.2458,  0.9060, -0.0373, -0.0468,  0.2032, -0.0401, -0.0104,  0.2512]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5517, -0.5225,  0.5920,  0.3906,  0.3982], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self, N, M):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.rand(N, M))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.sum() > 0:\n",
    "          output = self.weight.mv(input)\n",
    "        else:\n",
    "          output = self.weight + input\n",
    "        return output   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self, N, M):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.rand(N, M))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.sum() > 0:\n",
    "          output = self.weight.mv(input)\n",
    "        else:\n",
    "          output = self.weight + input\n",
    "        return output\n",
    "\n",
    "my_module = MyModule(10,20)\n",
    "sm = torch.jit.script(my_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(original_name=MyModule)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def forward(self,\\n    input: Tensor) -> Tensor:\\n  if bool(torch.gt(torch.sum(input), 0)):\\n    weight = self.weight\\n    output = torch.mv(weight, input)\\n  else:\\n    weight0 = self.weight\\n    output = torch.add(weight0, input)\\n  return output\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    input: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(input), 0)):\n",
      "    weight = self.weight\n",
      "    output = torch.mv(weight, input)\n",
      "  else:\n",
      "    weight0 = self.weight\n",
      "    output = torch.add(weight0, input)\n",
      "  return output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sm.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(\"traced_resnet_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lrbonta/anaconda3/lib/python3.9/site-packages/torch/share/cmake\n"
     ]
    }
   ],
   "source": [
    "print(torch.utils.cmake_prefix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0aabe1622f6e42d5abe5f4600d0172c77afb141d07594a524ba2dbe93890334e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
